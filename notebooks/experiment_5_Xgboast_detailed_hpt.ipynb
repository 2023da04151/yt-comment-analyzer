{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GVVb-0pOKV2",
        "outputId": "37561fa7-d19a-42ab-fc9f-91f07e759fec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.1.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Collecting dagshub\n",
            "  Downloading dagshub-0.5.10-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mlflow-skinny==3.1.1 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.1.1-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading databricks_sdk-0.58.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.116.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (8.7.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (4.14.1)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.1->mlflow) (0.35.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Collecting appdirs>=1.4.4 (from dagshub)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (13.9.4)\n",
            "Collecting dacite~=1.6.0 (from dagshub)\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.5.0)\n",
            "Collecting gql[requests] (from dagshub)\n",
            "  Downloading gql-3.5.3-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting dataclasses-json (from dagshub)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting treelib>=1.6.4 (from dagshub)\n",
            "  Downloading treelib-1.8.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pathvalidate>=3.0.0 (from dagshub)\n",
            "  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\n",
            "Collecting boto3 (from dagshub)\n",
            "  Downloading boto3-1.39.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting semver (from dagshub)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting dagshub-annotation-converter>=0.1.5 (from dagshub)\n",
            "  Downloading dagshub_annotation_converter-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.2.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (4.0.12)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->dagshub) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.3)\n",
            "Collecting botocore<1.40.0,>=1.39.4 (from boto3->dagshub)\n",
            "  Downloading botocore-1.39.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->dagshub)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->dagshub)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->dagshub)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->dagshub)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.20.1)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.1->mlflow) (0.46.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.1->mlflow) (5.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.1->mlflow) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\n",
            "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.1->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.1->mlflow) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.1->mlflow) (3.4.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.1->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.1.1-py3-none-any.whl (24.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dagshub-0.5.10-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading dagshub_annotation_converter-0.1.10-py3-none-any.whl (33 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
            "Downloading treelib-1.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading boto3-1.39.4-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading botocore-1.39.4-py3-none-any.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.58.0-py3-none-any.whl (741 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m741.4/741.4 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading gql-3.5.3-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: appdirs, treelib, semver, pathvalidate, mypy-extensions, marshmallow, jmespath, gunicorn, graphql-core, dacite, colorlog, backoff, typing-inspect, opentelemetry-api, graphql-relay, gql, docker, botocore, alembic, s3transfer, optuna, opentelemetry-semantic-conventions, graphene, dataclasses-json, databricks-sdk, dagshub-annotation-converter, opentelemetry-sdk, boto3, mlflow-skinny, dagshub, mlflow\n",
            "Successfully installed alembic-1.16.4 appdirs-1.4.4 backoff-2.2.1 boto3-1.39.4 botocore-1.39.4 colorlog-6.9.0 dacite-1.6.0 dagshub-0.5.10 dagshub-annotation-converter-0.1.10 databricks-sdk-0.58.0 dataclasses-json-0.6.7 docker-7.1.0 gql-3.5.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 marshmallow-3.26.1 mlflow-3.1.1 mlflow-skinny-3.1.1 mypy-extensions-1.1.0 opentelemetry-api-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 optuna-4.4.0 pathvalidate-3.3.1 s3transfer-0.13.0 semver-3.0.4 treelib-1.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow  optuna  lightgbm dagshub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "LVBQ5N5oOjC4",
        "outputId": "c415b540-7728-414a-928e-c81c4e5fcc61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠴</span> Waiting for authorization\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m⠴\u001b[0m Waiting for authorization\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as AMR-ITH\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as AMR-ITH\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"AMR-ITH/yt-comment-analyzer\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"AMR-ITH/yt-comment-analyzer\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository AMR-ITH/yt-comment-analyzer initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository AMR-ITH/yt-comment-analyzer initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import dagshub\n",
        "import mlflow\n",
        "dagshub.init(repo_owner='AMR-ITH', repo_name='yt-comment-analyzer', mlflow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFhcrAIlPJ4u",
        "outputId": "90416943-67ed-462a-f03b-59d2890e760c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='mlflow-artifacts:/72b4a6680da6444f8672000d54583b16', creation_time=1752307675190, experiment_id='10', last_update_time=1752307675190, lifecycle_stage='active', name='exp5 Best model HP Tuning', tags={}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"exp5 Best model HP Tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueABlDAMPtSJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JG93V6PgP8DC",
        "outputId": "2dd7100e-9ccf-4b49-ad61-9859412f98e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 36662,\n  \"fields\": [\n    {\n      \"column\": \"clean_comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36236,\n        \"samples\": [\n          \"modi peace prize not hindutva issue\",\n          \"people tend think blood but mentioned repeatedly modi also modi success success but job right question asking question opposition lost public confidence 2014 nda represents people logical thing would look work\",\n          \"team support god played team hang post retirement support team particular neither selected pujara root pity want indian guy perform well smash foreigner started supporting srh year back yuvraj yep old school yuvi fanboy bhuvi ideal would mumbai win dhoni raina jadeja performing well csk dhoni hitting fastest ipl yuvraj getting 1st t20 century ashwin getting fifer getting kxip final bhajji getting man match award csk koach brohit raina tight competition orange cap bumrah bhuvi sending middle stump cartwheeling back bowling chriss lynn villiers respectively yuzi buoy thechesschampion check mate glenn maxwell insert lifening snow patrol read ever wanted life\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          -1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4fa0200b-2c5c-47a8-a31f-840841690ca6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>family mormon never tried explain still stare ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buddhism much lot compatible christianity espe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seriously say thing first get complex explain ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>learned want teach different focus goal not wr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>benefit may want read living buddha living chr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fa0200b-2c5c-47a8-a31f-840841690ca6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fa0200b-2c5c-47a8-a31f-840841690ca6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fa0200b-2c5c-47a8-a31f-840841690ca6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6974cf75-3083-4530-b2ae-6b4c40ddd1b3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6974cf75-3083-4530-b2ae-6b4c40ddd1b3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6974cf75-3083-4530-b2ae-6b4c40ddd1b3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                       clean_comment  category\n",
              "0  family mormon never tried explain still stare ...         1\n",
              "1  buddhism much lot compatible christianity espe...         1\n",
              "2  seriously say thing first get complex explain ...        -1\n",
              "3  learned want teach different focus goal not wr...         0\n",
              "4  benefit may want read living buddha living chr...         1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/reddit_preprocessing.csv\").dropna()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YSYnKv1P_Mz",
        "outputId": "3a908377-f635-459c-ebc2-d1f37ddd520f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36662, 2)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kcp80Cdsp7Nu",
        "outputId": "231e5ee5-76ed-4a0e-93b3-20ddf3b435bf"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running XGBoost experiment with max_features=3000 ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-13 01:34:42,588] A new study created in memory with name: no-name-91968eb7-2560-47e8-bc1a-86e9ee159eee\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:34:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 01:35:45,565] Trial 0 finished with value: 0.7057138960861857 and parameters: {'n_estimators': 490, 'learning_rate': 0.027243341648791514, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.5763719294154306, 'colsample_bytree': 0.629745475740739, 'colsample_bylevel': 0.898454751570512, 'colsample_bynode': 0.9766281526346697, 'reg_alpha': 0.004213089923746137, 'reg_lambda': 5.668191317381823, 'gamma': 0.41895216876576064}. Best is trial 0 with value: 0.7057138960861857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:35:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 01:49:38,767] Trial 1 finished with value: 0.6998499931815082 and parameters: {'n_estimators': 767, 'learning_rate': 0.003991827882407467, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8110718787991018, 'colsample_bytree': 0.750550933416551, 'colsample_bylevel': 0.8163968787568453, 'colsample_bynode': 0.6164781157834922, 'reg_alpha': 0.436950347636228, 'reg_lambda': 2.4922034670499547, 'gamma': 0.0004296179666553343}. Best is trial 0 with value: 0.7057138960861857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:49:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 01:56:50,932] Trial 2 finished with value: 0.6548479476339834 and parameters: {'n_estimators': 948, 'learning_rate': 0.00035869088672599406, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.6213099204428674, 'colsample_bytree': 0.725709370122498, 'colsample_bylevel': 0.6051486930347141, 'colsample_bynode': 0.7520102502463655, 'reg_alpha': 4.814743329486589, 'reg_lambda': 0.0005100762147142195, 'gamma': 0.01585648187737452}. Best is trial 0 with value: 0.7057138960861857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [01:56:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:10:21,203] Trial 3 finished with value: 0.7205782081003682 and parameters: {'n_estimators': 702, 'learning_rate': 0.0036503474844349878, 'max_depth': 15, 'min_child_weight': 7, 'subsample': 0.5975074023487055, 'colsample_bytree': 0.8228365344605297, 'colsample_bylevel': 0.9667068667466374, 'colsample_bynode': 0.6642688711949294, 'reg_alpha': 0.02123783204138715, 'reg_lambda': 0.0019424537724069008, 'gamma': 0.17461037599039864}. Best is trial 3 with value: 0.7205782081003682.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:10:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:11:10,901] Trial 4 finished with value: 0.6444838401745534 and parameters: {'n_estimators': 256, 'learning_rate': 0.006906191303725814, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.9330377891014555, 'colsample_bytree': 0.6982853486187979, 'colsample_bylevel': 0.9393765342769942, 'colsample_bynode': 0.5997450333344191, 'reg_alpha': 5.8357299658249016, 'reg_lambda': 0.00045735036782094783, 'gamma': 0.5814700030812604}. Best is trial 3 with value: 0.7205782081003682.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:11:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:16:52,331] Trial 5 finished with value: 0.6468021273694259 and parameters: {'n_estimators': 945, 'learning_rate': 0.0015240917183947619, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.7944733476607324, 'colsample_bytree': 0.9757442485195763, 'colsample_bylevel': 0.7491863078885288, 'colsample_bynode': 0.8251742140325022, 'reg_alpha': 0.2402027807045429, 'reg_lambda': 0.02699613565425055, 'gamma': 0.014821525641550244}. Best is trial 3 with value: 0.7205782081003682.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:16:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:23:59,027] Trial 6 finished with value: 0.7443065593890631 and parameters: {'n_estimators': 812, 'learning_rate': 0.010649848574371682, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.833783277483128, 'colsample_bytree': 0.7024476200221306, 'colsample_bylevel': 0.5009446167304223, 'colsample_bynode': 0.7777993668757208, 'reg_alpha': 2.1267502184888225, 'reg_lambda': 0.0086330638266853, 'gamma': 0.0429055821518276}. Best is trial 6 with value: 0.7443065593890631.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:23:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:33:31,399] Trial 7 finished with value: 0.7331242329196782 and parameters: {'n_estimators': 829, 'learning_rate': 0.007527223426969733, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8555294719230437, 'colsample_bytree': 0.5492756780296784, 'colsample_bylevel': 0.7341653117641735, 'colsample_bynode': 0.5673034253404072, 'reg_alpha': 0.05573721181473215, 'reg_lambda': 3.1185808247968496, 'gamma': 0.004094036691584467}. Best is trial 6 with value: 0.7443065593890631.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:33:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:35:25,234] Trial 8 finished with value: 0.6564843856538933 and parameters: {'n_estimators': 484, 'learning_rate': 0.0029152752618634343, 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.7757963364267101, 'colsample_bytree': 0.5814043868471306, 'colsample_bylevel': 0.6971760540347789, 'colsample_bynode': 0.6306661214104602, 'reg_alpha': 1.5049611861413839, 'reg_lambda': 2.7894001901084176, 'gamma': 0.0004484559074458107}. Best is trial 6 with value: 0.7443065593890631.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:35:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:36:51,288] Trial 9 finished with value: 0.6511659620891859 and parameters: {'n_estimators': 343, 'learning_rate': 0.0025430538610867956, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.7187194398605861, 'colsample_bytree': 0.5476602732903504, 'colsample_bylevel': 0.822315849913928, 'colsample_bynode': 0.8521235119435122, 'reg_alpha': 0.3878230126499086, 'reg_lambda': 0.9177210956411005, 'gamma': 0.0011236749485946413}. Best is trial 6 with value: 0.7443065593890631.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:36:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:38:29,135] Trial 10 finished with value: 0.804854766125733 and parameters: {'n_estimators': 639, 'learning_rate': 0.0600659902387598, 'max_depth': 14, 'min_child_weight': 3, 'subsample': 0.9995320225068483, 'colsample_bytree': 0.8793138873281452, 'colsample_bylevel': 0.5391456493986861, 'colsample_bynode': 0.5033154796020867, 'reg_alpha': 0.00013289236784015093, 'reg_lambda': 0.02010060339180842, 'gamma': 7.403252716462094}. Best is trial 10 with value: 0.804854766125733.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:38:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:39:29,914] Trial 11 finished with value: 0.7918996318014455 and parameters: {'n_estimators': 628, 'learning_rate': 0.08858414402478731, 'max_depth': 14, 'min_child_weight': 3, 'subsample': 0.9997558712449719, 'colsample_bytree': 0.9005240048738277, 'colsample_bylevel': 0.5000152000521445, 'colsample_bynode': 0.5103887089022279, 'reg_alpha': 0.00016154499661497716, 'reg_lambda': 0.02218050763864942, 'gamma': 9.672307655524959}. Best is trial 10 with value: 0.804854766125733.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:39:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:40:46,087] Trial 12 finished with value: 0.812491476885313 and parameters: {'n_estimators': 642, 'learning_rate': 0.08920679747780792, 'max_depth': 15, 'min_child_weight': 3, 'subsample': 0.986211096760969, 'colsample_bytree': 0.9193180322345267, 'colsample_bylevel': 0.5048232084373203, 'colsample_bynode': 0.5033139642886059, 'reg_alpha': 0.00010167975674722856, 'reg_lambda': 0.18989566171973124, 'gamma': 6.79719166379877}. Best is trial 12 with value: 0.812491476885313.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:40:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:41:51,948] Trial 13 finished with value: 0.7903995636165281 and parameters: {'n_estimators': 581, 'learning_rate': 0.08564002401673274, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.998361325976718, 'colsample_bytree': 0.8853010441855583, 'colsample_bylevel': 0.5867992230728016, 'colsample_bynode': 0.5060728837096471, 'reg_alpha': 0.00010453466423757372, 'reg_lambda': 0.23359562021654728, 'gamma': 9.842573995510964}. Best is trial 12 with value: 0.812491476885313.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:41:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:45:19,559] Trial 14 finished with value: 0.7916268921314605 and parameters: {'n_estimators': 390, 'learning_rate': 0.03164231768515035, 'max_depth': 12, 'min_child_weight': 3, 'subsample': 0.9123378880759102, 'colsample_bytree': 0.9944646830680762, 'colsample_bylevel': 0.6036483835963256, 'colsample_bynode': 0.6769177844197838, 'reg_alpha': 0.0007936303886286983, 'reg_lambda': 0.2507066579821482, 'gamma': 1.8228888886240384}. Best is trial 12 with value: 0.812491476885313.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:45:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:45:59,805] Trial 15 finished with value: 0.7174417018955407 and parameters: {'n_estimators': 106, 'learning_rate': 0.029970604004545025, 'max_depth': 12, 'min_child_weight': 10, 'subsample': 0.7026347131640591, 'colsample_bytree': 0.8835201301054396, 'colsample_bylevel': 0.5664389778778328, 'colsample_bynode': 0.5258895674397803, 'reg_alpha': 0.0006748670822250358, 'reg_lambda': 0.15596065735761358, 'gamma': 1.1683332998104332}. Best is trial 12 with value: 0.812491476885313.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:45:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 02:56:00,471] Trial 16 finished with value: 0.6772126005727533 and parameters: {'n_estimators': 639, 'learning_rate': 0.00019835112205815827, 'max_depth': 15, 'min_child_weight': 4, 'subsample': 0.9199898537329048, 'colsample_bytree': 0.8167651477690823, 'colsample_bylevel': 0.6606162274639935, 'colsample_bynode': 0.6872676827619182, 'reg_alpha': 0.0012370662383386084, 'reg_lambda': 0.00595450981949304, 'gamma': 2.341600252175269}. Best is trial 12 with value: 0.812491476885313.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:56:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:00:05,522] Trial 17 finished with value: 0.833765171144143 and parameters: {'n_estimators': 514, 'learning_rate': 0.048663534901288906, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.5160348834140127, 'colsample_bytree': 0.9469337076316151, 'colsample_bylevel': 0.5445741309338629, 'colsample_bynode': 0.5673279696288891, 'reg_alpha': 0.006316582588123725, 'reg_lambda': 0.07751756698824867, 'gamma': 0.10819223879490882}. Best is trial 17 with value: 0.833765171144143.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:00:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:04:41,293] Trial 18 finished with value: 0.7616255284331106 and parameters: {'n_estimators': 425, 'learning_rate': 0.018953027196723024, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.5111365554872411, 'colsample_bytree': 0.9370767734023344, 'colsample_bylevel': 0.6371242126752743, 'colsample_bynode': 0.5746596674711886, 'reg_alpha': 0.008241381478030744, 'reg_lambda': 0.09398284993302462, 'gamma': 0.08665704259082285}. Best is trial 17 with value: 0.833765171144143.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:04:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:07:24,237] Trial 19 finished with value: 0.6350743215600709 and parameters: {'n_estimators': 290, 'learning_rate': 0.0008484685857826481, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6472848052309109, 'colsample_bytree': 0.7967052303620377, 'colsample_bylevel': 0.681795264409104, 'colsample_bynode': 0.9404337941412564, 'reg_alpha': 0.05315807395603533, 'reg_lambda': 0.6811115693440999, 'gamma': 0.0038249961991782258}. Best is trial 17 with value: 0.833765171144143.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:07:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:11:32,649] Trial 20 finished with value: 0.8311741442792854 and parameters: {'n_estimators': 472, 'learning_rate': 0.04587006259408812, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.5299249762512657, 'colsample_bytree': 0.941463859438267, 'colsample_bylevel': 0.5550793391839961, 'colsample_bynode': 0.5599696430912954, 'reg_alpha': 0.0032608577247230535, 'reg_lambda': 0.06428109874183624, 'gamma': 0.19820740021928943}. Best is trial 17 with value: 0.833765171144143.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:11:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:17:08,966] Trial 21 finished with value: 0.7747170325923906 and parameters: {'n_estimators': 521, 'learning_rate': 0.01582091123593972, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.5026646140955631, 'colsample_bytree': 0.9489414186626548, 'colsample_bylevel': 0.5354265502680111, 'colsample_bynode': 0.5561622005971762, 'reg_alpha': 0.0036362411283430746, 'reg_lambda': 0.060213469492450086, 'gamma': 0.2868950920922851}. Best is trial 17 with value: 0.833765171144143.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:17:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:21:45,793] Trial 22 finished with value: 0.8385381153688805 and parameters: {'n_estimators': 553, 'learning_rate': 0.051669665165407545, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.5520570306591945, 'colsample_bytree': 0.9452574615713122, 'colsample_bylevel': 0.5442791429260968, 'colsample_bynode': 0.5647189399845963, 'reg_alpha': 0.00048405702355414293, 'reg_lambda': 0.6837598267499744, 'gamma': 0.07993020236707589}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:21:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:26:02,497] Trial 23 finished with value: 0.802400109095868 and parameters: {'n_estimators': 431, 'learning_rate': 0.034006682136137806, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.5509256345810442, 'colsample_bytree': 0.850310194164583, 'colsample_bylevel': 0.6320780327793342, 'colsample_bynode': 0.6358218116061137, 'reg_alpha': 0.015821582025859083, 'reg_lambda': 0.44477184981726214, 'gamma': 0.07372989357507144}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:26:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:28:52,739] Trial 24 finished with value: 0.7733533342424656 and parameters: {'n_estimators': 195, 'learning_rate': 0.04174328420916239, 'max_depth': 13, 'min_child_weight': 2, 'subsample': 0.5403554036808947, 'colsample_bytree': 0.9723813025658049, 'colsample_bylevel': 0.5613883389937775, 'colsample_bynode': 0.7227909813532549, 'reg_alpha': 0.001966496693309628, 'reg_lambda': 0.055189983369649795, 'gamma': 0.1293678603089701}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:28:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:33:33,373] Trial 25 finished with value: 0.7676258011727806 and parameters: {'n_estimators': 571, 'learning_rate': 0.016833699161263024, 'max_depth': 11, 'min_child_weight': 4, 'subsample': 0.6564248832777799, 'colsample_bytree': 0.9359551959650315, 'colsample_bylevel': 0.5471781332720496, 'colsample_bynode': 0.5968966487116473, 'reg_alpha': 0.006643884396065011, 'reg_lambda': 1.0629094197132125, 'gamma': 0.03415151118859635}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:33:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:39:41,591] Trial 26 finished with value: 0.8116732578753579 and parameters: {'n_estimators': 360, 'learning_rate': 0.04185702130146317, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5545606541574153, 'colsample_bytree': 0.7702719082680478, 'colsample_bylevel': 0.8248216850478199, 'colsample_bynode': 0.5611567493196017, 'reg_alpha': 0.00031780090680134194, 'reg_lambda': 0.0001339883060626736, 'gamma': 0.010078355574344139}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:39:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:44:08,365] Trial 27 finished with value: 0.8288558570844129 and parameters: {'n_estimators': 481, 'learning_rate': 0.05378112484467058, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.5908626801041532, 'colsample_bytree': 0.9947126495856609, 'colsample_bylevel': 0.6369260294734224, 'colsample_bynode': 0.5488579171282182, 'reg_alpha': 0.0004637192052232149, 'reg_lambda': 0.006434971569134235, 'gamma': 0.0001071506492075373}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:44:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:46:25,505] Trial 28 finished with value: 0.7264421110050456 and parameters: {'n_estimators': 547, 'learning_rate': 0.010773128744204665, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.5023089119981845, 'colsample_bytree': 0.8557235595541964, 'colsample_bylevel': 0.5879694446758679, 'colsample_bynode': 0.6584281583281855, 'reg_alpha': 0.0021283383016006707, 'reg_lambda': 0.059944815968821716, 'gamma': 0.866001765201562}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:46:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:55:25,114] Trial 29 finished with value: 0.7778535387972181 and parameters: {'n_estimators': 712, 'learning_rate': 0.017274660236914815, 'max_depth': 13, 'min_child_weight': 4, 'subsample': 0.6721334210875372, 'colsample_bytree': 0.9550012331831971, 'colsample_bylevel': 0.8595303481882121, 'colsample_bynode': 0.7084213547061786, 'reg_alpha': 0.0033881243653015787, 'reg_lambda': 8.646746855210926, 'gamma': 0.2518803017716976}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:55:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 03:58:05,981] Trial 30 finished with value: 0.8208100368198554 and parameters: {'n_estimators': 458, 'learning_rate': 0.05889341380185472, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.6131570144858601, 'colsample_bytree': 0.6519105689096723, 'colsample_bylevel': 0.7230853989434611, 'colsample_bynode': 0.992967665516674, 'reg_alpha': 0.008958217847327591, 'reg_lambda': 0.42418406456495117, 'gamma': 0.4505198664077171}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:58:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:02:13,705] Trial 31 finished with value: 0.8310377744442929 and parameters: {'n_estimators': 489, 'learning_rate': 0.053189718880870984, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.5732560551622843, 'colsample_bytree': 0.999930599755526, 'colsample_bylevel': 0.6233288349440886, 'colsample_bynode': 0.5440416402887973, 'reg_alpha': 0.0003879549828751549, 'reg_lambda': 0.008715661673566334, 'gamma': 0.06383002688217444}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:02:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:08:22,766] Trial 32 finished with value: 0.7948997681712805 and parameters: {'n_estimators': 521, 'learning_rate': 0.02403961055237602, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.5676670125825459, 'colsample_bytree': 0.9175784819712977, 'colsample_bylevel': 0.5307606012099025, 'colsample_bynode': 0.5948527798640006, 'reg_alpha': 0.00030931100664939555, 'reg_lambda': 0.0021625364625932468, 'gamma': 0.071748994662834}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:08:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:11:17,019] Trial 33 finished with value: 0.8109914087003954 and parameters: {'n_estimators': 312, 'learning_rate': 0.06072899611469915, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5312195912917115, 'colsample_bytree': 0.967879315211618, 'colsample_bylevel': 0.7814314621473819, 'colsample_bynode': 0.5377617246278674, 'reg_alpha': 0.0010626428817892828, 'reg_lambda': 0.012229021370420116, 'gamma': 0.035915348582706556}. Best is trial 22 with value: 0.8385381153688805.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:11:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:14:52,749] Trial 34 finished with value: 0.8404472930587754 and parameters: {'n_estimators': 390, 'learning_rate': 0.09323069276121387, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.582243400779415, 'colsample_bytree': 0.9968371481296349, 'colsample_bylevel': 0.5874880244784142, 'colsample_bynode': 0.6185662664432869, 'reg_alpha': 0.0002719846732275456, 'reg_lambda': 0.0029308097922774307, 'gamma': 0.14667820083602565}. Best is trial 34 with value: 0.8404472930587754.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:14:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:19:13,666] Trial 35 finished with value: 0.8460384562934679 and parameters: {'n_estimators': 391, 'learning_rate': 0.09284610673430381, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.6223685991974504, 'colsample_bytree': 0.9145748533032563, 'colsample_bylevel': 0.5821543854551949, 'colsample_bynode': 0.6291459951230686, 'reg_alpha': 0.0013959750627057092, 'reg_lambda': 0.002982834215533974, 'gamma': 0.19733966862439623}. Best is trial 35 with value: 0.8460384562934679.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:19:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:24:12,834] Trial 36 finished with value: 0.8453566071185054 and parameters: {'n_estimators': 392, 'learning_rate': 0.09882402388691112, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.627349628764831, 'colsample_bytree': 0.9153126397146332, 'colsample_bylevel': 0.5831778107942152, 'colsample_bynode': 0.620313622110295, 'reg_alpha': 0.0015794755989899862, 'reg_lambda': 0.0015187201022670643, 'gamma': 0.008362948533482637}. Best is trial 35 with value: 0.8460384562934679.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:24:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:27:23,208] Trial 37 finished with value: 0.8274921587344879 and parameters: {'n_estimators': 206, 'learning_rate': 0.09938021278531972, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.6267646457380449, 'colsample_bytree': 0.9147509843070631, 'colsample_bylevel': 0.585811504257841, 'colsample_bynode': 0.6437351877216598, 'reg_alpha': 0.00021247499371461985, 'reg_lambda': 0.0017837421987047142, 'gamma': 0.01630757631834657}. Best is trial 35 with value: 0.8460384562934679.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:27:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:41:20,311] Trial 38 finished with value: 0.6784399290876858 and parameters: {'n_estimators': 398, 'learning_rate': 0.0006831016921669235, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.6935849440907338, 'colsample_bytree': 0.8583629420644481, 'colsample_bylevel': 0.6780801666027855, 'colsample_bynode': 0.6107831774827351, 'reg_alpha': 0.0012873436574998137, 'reg_lambda': 0.0004911257584062013, 'gamma': 0.0034249803208550524}. Best is trial 35 with value: 0.8460384562934679.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:41:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2025-07-13 04:49:16,707] Trial 39 finished with value: 0.7013500613664257 and parameters: {'n_estimators': 282, 'learning_rate': 0.006029611613695126, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5975542108518084, 'colsample_bytree': 0.7385556095660899, 'colsample_bylevel': 0.6075039747422485, 'colsample_bynode': 0.7682938026331985, 'reg_alpha': 0.0005709374620171306, 'reg_lambda': 0.0011146144885170724, 'gamma': 0.008759024311244002}. Best is trial 35 with value: 0.8460384562934679.\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=7, read=6, redirect=7, status=7)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /AMR-ITH/yt-comment-analyzer.mlflow/api/2.0/mlflow/runs/create\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [04:49:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run Trial_Best-hp-MaxFeatures-3000_XGBoost_Trigrams_MaxFeatures_3000 at: https://dagshub.com/AMR-ITH/yt-comment-analyzer.mlflow/#/experiments/10/runs/4284600d5ac74f5c9bc4efabcf138fd6\n",
            "🧪 View experiment at: https://dagshub.com/AMR-ITH/yt-comment-analyzer.mlflow/#/experiments/10\n",
            "Best accuracy for max_features=3000: 0.8460\n",
            "Best parameters: {'n_estimators': 391, 'learning_rate': 0.09284610673430381, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.6223685991974504, 'colsample_bytree': 0.9145748533032563, 'colsample_bylevel': 0.5821543854551949, 'colsample_bynode': 0.6291459951230686, 'reg_alpha': 0.0013959750627057092, 'reg_lambda': 0.002982834215533974, 'gamma': 0.19733966862439623}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a33fe515-ad14-42f4-b980-557f6a052aef\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a33fe515-ad14-42f4-b980-557f6a052aef\")) {                    Plotly.newPlot(                        \"a33fe515-ad14-42f4-b980-557f6a052aef\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"reg_alpha (FloatDistribution): 0.00012517597901877704\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"subsample (FloatDistribution): 0.003082449281154331\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"min_child_weight (IntDistribution): 0.0031563377031616074\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"gamma (FloatDistribution): 0.003317753111127902\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_estimators (IntDistribution): 0.003769946814853113\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"colsample_bynode (FloatDistribution): 0.003906998603918782\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"colsample_bylevel (FloatDistribution): 0.005274112517281107\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"max_depth (IntDistribution): 0.00782923413953447\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"reg_lambda (FloatDistribution): 0.012449439733196637\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"colsample_bytree (FloatDistribution): 0.036501908985450464\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.920586643131303\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"0.01\",\"0.04\",\"0.92\"],\"textposition\":\"outside\",\"x\":[0.00012517597901877704,0.003082449281154331,0.0031563377031616074,0.003317753111127902,0.003769946814853113,0.003906998603918782,0.005274112517281107,0.00782923413953447,0.012449439733196637,0.036501908985450464,0.920586643131303],\"y\":[\"reg_alpha\",\"subsample\",\"min_child_weight\",\"gamma\",\"n_estimators\",\"colsample_bynode\",\"colsample_bylevel\",\"max_depth\",\"reg_lambda\",\"colsample_bytree\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a33fe515-ad14-42f4-b980-557f6a052aef');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6b491fd0-c52d-4af4-b09b-c65dfe686fca\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b491fd0-c52d-4af4-b09b-c65dfe686fca\")) {                    Plotly.newPlot(                        \"6b491fd0-c52d-4af4-b09b-c65dfe686fca\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"y\":[0.7057138960861857,0.6998499931815082,0.6548479476339834,0.7205782081003682,0.6444838401745534,0.6468021273694259,0.7443065593890631,0.7331242329196782,0.6564843856538933,0.6511659620891859,0.804854766125733,0.7918996318014455,0.812491476885313,0.7903995636165281,0.7916268921314605,0.7174417018955407,0.6772126005727533,0.833765171144143,0.7616255284331106,0.6350743215600709,0.8311741442792854,0.7747170325923906,0.8385381153688805,0.802400109095868,0.7733533342424656,0.7676258011727806,0.8116732578753579,0.8288558570844129,0.7264421110050456,0.7778535387972181,0.8208100368198554,0.8310377744442929,0.7948997681712805,0.8109914087003954,0.8404472930587754,0.8460384562934679,0.8453566071185054,0.8274921587344879,0.6784399290876858,0.7013500613664257],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"y\":[0.7057138960861857,0.7057138960861857,0.7057138960861857,0.7205782081003682,0.7205782081003682,0.7205782081003682,0.7443065593890631,0.7443065593890631,0.7443065593890631,0.7443065593890631,0.804854766125733,0.804854766125733,0.812491476885313,0.812491476885313,0.812491476885313,0.812491476885313,0.812491476885313,0.833765171144143,0.833765171144143,0.833765171144143,0.833765171144143,0.833765171144143,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8385381153688805,0.8404472930587754,0.8460384562934679,0.8460384562934679,0.8460384562934679,0.8460384562934679,0.8460384562934679],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6b491fd0-c52d-4af4-b09b-c65dfe686fca');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running XGBoost experiment with max_features=10000 ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-13 04:54:51,684] A new study created in memory with name: no-name-b1680b5a-fdb5-46a1-83b1-59677759b21d\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[04:54:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 05:01:05,148] Trial 0 finished with value: 0.6065730260466384 and parameters: {'n_estimators': 858, 'learning_rate': 0.0003754954547468287, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.8258849343625038, 'colsample_bytree': 0.9454102354443934, 'colsample_bylevel': 0.707011525661584, 'colsample_bynode': 0.7739622585095051, 'reg_alpha': 0.6747958972812315, 'reg_lambda': 0.01425478839622739, 'gamma': 0.015080387987167767}. Best is trial 0 with value: 0.6065730260466384.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[05:01:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 05:03:02,552] Trial 1 finished with value: 0.7314877948997681 and parameters: {'n_estimators': 348, 'learning_rate': 0.038448599694801654, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.7909060228686642, 'colsample_bytree': 0.9846945835853433, 'colsample_bylevel': 0.5288330696718271, 'colsample_bynode': 0.7504747384654107, 'reg_alpha': 4.508796087699667, 'reg_lambda': 3.4080295566084917, 'gamma': 0.018252534079414517}. Best is trial 1 with value: 0.7314877948997681.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[05:03:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 05:06:51,860] Trial 2 finished with value: 0.7329878630846857 and parameters: {'n_estimators': 923, 'learning_rate': 0.020391678265675964, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.683909039295121, 'colsample_bytree': 0.9734867786857258, 'colsample_bylevel': 0.8921682224250375, 'colsample_bynode': 0.704624722504773, 'reg_alpha': 6.391356378277901, 'reg_lambda': 1.913316841443174, 'gamma': 0.020682482462126745}. Best is trial 2 with value: 0.7329878630846857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[05:06:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 05:16:33,371] Trial 3 finished with value: 0.6678030819582709 and parameters: {'n_estimators': 863, 'learning_rate': 0.00040804740323471047, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.9855604525424402, 'colsample_bytree': 0.7115662493376481, 'colsample_bylevel': 0.6889179414298352, 'colsample_bynode': 0.6011750275649661, 'reg_alpha': 0.3305876426688029, 'reg_lambda': 7.385506214084211, 'gamma': 3.0057705124040384}. Best is trial 2 with value: 0.7329878630846857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[05:16:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 05:19:25,770] Trial 4 finished with value: 0.602891040501841 and parameters: {'n_estimators': 482, 'learning_rate': 0.0011599621843092133, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.8582643851873832, 'colsample_bytree': 0.8877350680268414, 'colsample_bylevel': 0.9031136857224275, 'colsample_bynode': 0.9736761952851533, 'reg_alpha': 0.0012613603959592023, 'reg_lambda': 0.040051622674930454, 'gamma': 0.06537478811060873}. Best is trial 2 with value: 0.7329878630846857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[05:19:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 05:22:49,366] Trial 5 finished with value: 0.6748943133778809 and parameters: {'n_estimators': 320, 'learning_rate': 0.0005304878749105912, 'max_depth': 11, 'min_child_weight': 9, 'subsample': 0.5628133126859143, 'colsample_bytree': 0.5351287899005979, 'colsample_bylevel': 0.7654512924309604, 'colsample_bynode': 0.6985661729779173, 'reg_alpha': 0.002973557774451139, 'reg_lambda': 1.3028077410314338, 'gamma': 0.05269703268656959}. Best is trial 2 with value: 0.7329878630846857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[05:22:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 05:40:14,792] Trial 6 finished with value: 0.6616664393836084 and parameters: {'n_estimators': 483, 'learning_rate': 0.00011941954538301294, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9048772429602191, 'colsample_bytree': 0.7922268142721198, 'colsample_bylevel': 0.8742686463631613, 'colsample_bynode': 0.9270547702031757, 'reg_alpha': 0.003091449834226961, 'reg_lambda': 0.008274368889146481, 'gamma': 0.024980440180670412}. Best is trial 2 with value: 0.7329878630846857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[05:40:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:21:57,446] Trial 7 finished with value: 0.6937133506068458 and parameters: {'n_estimators': 825, 'learning_rate': 0.0005206581627781055, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.5922915655390484, 'colsample_bytree': 0.5756872535315615, 'colsample_bylevel': 0.9552335643149512, 'colsample_bynode': 0.9253453042155828, 'reg_alpha': 0.006742094341910912, 'reg_lambda': 0.003711681014122345, 'gamma': 0.03255375851984754}. Best is trial 2 with value: 0.7329878630846857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:21:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:25:58,873] Trial 8 finished with value: 0.6496658939042683 and parameters: {'n_estimators': 598, 'learning_rate': 0.0003542607639684427, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.7411229442115561, 'colsample_bytree': 0.5479109779418411, 'colsample_bylevel': 0.5360964730651832, 'colsample_bynode': 0.9167082185067492, 'reg_alpha': 0.004742971024690717, 'reg_lambda': 4.666111351742679, 'gamma': 3.1745364746588414}. Best is trial 2 with value: 0.7329878630846857.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:25:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:28:25,560] Trial 9 finished with value: 0.792854220646393 and parameters: {'n_estimators': 174, 'learning_rate': 0.05495395638493642, 'max_depth': 15, 'min_child_weight': 10, 'subsample': 0.9482546278111763, 'colsample_bytree': 0.9560006180205978, 'colsample_bylevel': 0.8964653915633226, 'colsample_bynode': 0.5767152016330559, 'reg_alpha': 0.0626839722156628, 'reg_lambda': 0.001379121519435119, 'gamma': 1.2143793904110871}. Best is trial 9 with value: 0.792854220646393.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:28:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:33:14,675] Trial 10 finished with value: 0.6881221873721532 and parameters: {'n_estimators': 118, 'learning_rate': 0.00868699172987532, 'max_depth': 15, 'min_child_weight': 8, 'subsample': 0.9516496107515257, 'colsample_bytree': 0.8309985825647566, 'colsample_bylevel': 0.9934296227920748, 'colsample_bynode': 0.5114818533723636, 'reg_alpha': 0.00012329730276320973, 'reg_lambda': 0.00014963480329682093, 'gamma': 0.000612794739641004}. Best is trial 9 with value: 0.792854220646393.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:33:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:37:40,748] Trial 11 finished with value: 0.8401745533887904 and parameters: {'n_estimators': 686, 'learning_rate': 0.09469082337903878, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.6722549783489609, 'colsample_bytree': 0.9991777723013977, 'colsample_bylevel': 0.8269434476005193, 'colsample_bynode': 0.6242311510425718, 'reg_alpha': 0.09301479666185468, 'reg_lambda': 0.21757324410299225, 'gamma': 0.36432683122232357}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:37:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:41:10,902] Trial 12 finished with value: 0.8247647620346379 and parameters: {'n_estimators': 658, 'learning_rate': 0.08516547107374349, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.6686677933898554, 'colsample_bytree': 0.8943427111028036, 'colsample_bylevel': 0.7969358734025378, 'colsample_bynode': 0.5898306276630793, 'reg_alpha': 0.06812955711891498, 'reg_lambda': 0.1496124632766499, 'gamma': 0.6363543249186404}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:41:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:45:06,397] Trial 13 finished with value: 0.8328105822991955 and parameters: {'n_estimators': 678, 'learning_rate': 0.08858907934008226, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.6454105831081656, 'colsample_bytree': 0.8731739261872015, 'colsample_bylevel': 0.7960332622815968, 'colsample_bynode': 0.6216996276893165, 'reg_alpha': 0.05730523342557574, 'reg_lambda': 0.14213566888274293, 'gamma': 0.34498376131820724}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:45:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:50:11,296] Trial 14 finished with value: 0.7177144415655257 and parameters: {'n_estimators': 696, 'learning_rate': 0.007170161993112488, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.61771728661955, 'colsample_bytree': 0.7248234806888179, 'colsample_bylevel': 0.6338634840785391, 'colsample_bynode': 0.6516588380640819, 'reg_alpha': 0.3627952589847395, 'reg_lambda': 0.27261750866564893, 'gamma': 0.29440103436727527}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:50:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 06:59:47,959] Trial 15 finished with value: 0.775671621437338 and parameters: {'n_estimators': 731, 'learning_rate': 0.016560826933114968, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.5239908548737502, 'colsample_bytree': 0.8690484372628088, 'colsample_bylevel': 0.816367207384815, 'colsample_bynode': 0.8257036964665454, 'reg_alpha': 0.02271153935896808, 'reg_lambda': 0.27632113254503504, 'gamma': 0.0016967078297593135}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[06:59:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:03:01,594] Trial 16 finished with value: 0.6701213691531434 and parameters: {'n_estimators': 753, 'learning_rate': 0.0030401203550544666, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.7143354331076037, 'colsample_bytree': 0.6497100554939287, 'colsample_bylevel': 0.6375963151241537, 'colsample_bynode': 0.6458269779885449, 'reg_alpha': 0.030258946039635096, 'reg_lambda': 0.05938033971192854, 'gamma': 9.826208300538989}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:03:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:06:43,372] Trial 17 finished with value: 0.8359470885040229 and parameters: {'n_estimators': 580, 'learning_rate': 0.09690811107298769, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.6421961715373804, 'colsample_bytree': 0.7976533985181099, 'colsample_bylevel': 0.843704458435446, 'colsample_bynode': 0.5147590655506492, 'reg_alpha': 1.2135252398170047, 'reg_lambda': 0.560335529894261, 'gamma': 0.18060746383994947}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:06:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:11:26,909] Trial 18 finished with value: 0.797763534706123 and parameters: {'n_estimators': 537, 'learning_rate': 0.03380555728404315, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7668638410154113, 'colsample_bytree': 0.6338767052962632, 'colsample_bylevel': 0.8444798720185286, 'colsample_bynode': 0.5178929650012646, 'reg_alpha': 1.4119326336041707, 'reg_lambda': 0.6792643288737268, 'gamma': 0.14080651337168162}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:11:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:17:58,137] Trial 19 finished with value: 0.6930315014318833 and parameters: {'n_estimators': 393, 'learning_rate': 0.004262863260328848, 'max_depth': 13, 'min_child_weight': 6, 'subsample': 0.5075886562158787, 'colsample_bytree': 0.7801228285610295, 'colsample_bylevel': 0.7422500062514766, 'colsample_bynode': 0.5529917491700156, 'reg_alpha': 0.17726420293583914, 'reg_lambda': 0.5754364541388377, 'gamma': 0.005370039883632599}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:17:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:24:26,791] Trial 20 finished with value: 0.7935360698213555 and parameters: {'n_estimators': 971, 'learning_rate': 0.017337389313007275, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.5567852382096007, 'colsample_bytree': 0.6678027802473893, 'colsample_bylevel': 0.9417765424463495, 'colsample_bynode': 0.50198116092138, 'reg_alpha': 1.5166320858645501, 'reg_lambda': 0.07043876398536056, 'gamma': 0.00010124985597595175}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:24:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:28:04,218] Trial 21 finished with value: 0.8333560616391654 and parameters: {'n_estimators': 620, 'learning_rate': 0.09742070451080649, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.6384053611121642, 'colsample_bytree': 0.8426654013077761, 'colsample_bylevel': 0.8024391565316306, 'colsample_bynode': 0.6353516826014854, 'reg_alpha': 0.10062509913052999, 'reg_lambda': 0.1588551761051348, 'gamma': 0.22249980459137436}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:28:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:31:12,447] Trial 22 finished with value: 0.8291285967543979 and parameters: {'n_estimators': 598, 'learning_rate': 0.09520263283577071, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.70384742051615, 'colsample_bytree': 0.8164345568875138, 'colsample_bylevel': 0.8362203561405039, 'colsample_bynode': 0.6809729702745178, 'reg_alpha': 0.13900055743784234, 'reg_lambda': 0.6625647089844, 'gamma': 0.14295944109682257}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:31:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:34:21,523] Trial 23 finished with value: 0.8093549706804855 and parameters: {'n_estimators': 463, 'learning_rate': 0.043988266500058625, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.6336356153098572, 'colsample_bytree': 0.9253809123704022, 'colsample_bylevel': 0.7623647390475456, 'colsample_bynode': 0.5464070977463212, 'reg_alpha': 0.014015859697391735, 'reg_lambda': 0.02532788845387437, 'gamma': 1.2135683447363688}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:34:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:39:41,576] Trial 24 finished with value: 0.7798990863221056 and parameters: {'n_estimators': 573, 'learning_rate': 0.023092694087849853, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.5966060579606796, 'colsample_bytree': 0.7548663980793752, 'colsample_bylevel': 0.846669142309902, 'colsample_bynode': 0.8244287465611767, 'reg_alpha': 2.001103901048511, 'reg_lambda': 0.13900270581840485, 'gamma': 0.15156782170553135}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:39:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:43:12,182] Trial 25 finished with value: 0.8178099004500204 and parameters: {'n_estimators': 780, 'learning_rate': 0.054617807170774836, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.7226869120127146, 'colsample_bytree': 0.9992548400672808, 'colsample_bylevel': 0.7074301092813055, 'colsample_bynode': 0.6289240491416522, 'reg_alpha': 0.4520120152779766, 'reg_lambda': 1.299129118497627, 'gamma': 0.6758566976171683}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:43:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:50:05,845] Trial 26 finished with value: 0.7305332060548206 and parameters: {'n_estimators': 611, 'learning_rate': 0.010071007614797919, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.6596035113293616, 'colsample_bytree': 0.8484577399839273, 'colsample_bylevel': 0.9387822747398441, 'colsample_bynode': 0.5568990201649986, 'reg_alpha': 0.14859660181946788, 'reg_lambda': 0.34634575848985605, 'gamma': 0.0056833577781411635}. Best is trial 11 with value: 0.8401745533887904.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:50:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:54:11,918] Trial 27 finished with value: 0.8444020182735579 and parameters: {'n_estimators': 645, 'learning_rate': 0.0992856125849396, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.5701166162393628, 'colsample_bytree': 0.9157799963299006, 'colsample_bylevel': 0.8616852672926257, 'colsample_bynode': 0.6794431506557485, 'reg_alpha': 0.9424389486460987, 'reg_lambda': 0.09160131384298396, 'gamma': 0.07834491853463521}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:54:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:55:01,994] Trial 28 finished with value: 0.6773489704077458 and parameters: {'n_estimators': 263, 'learning_rate': 0.03163605578797455, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.5558935920046957, 'colsample_bytree': 0.9039067386301829, 'colsample_bylevel': 0.8638836277067066, 'colsample_bynode': 0.7269846824652069, 'reg_alpha': 9.69673742422541, 'reg_lambda': 0.0030117040040752575, 'gamma': 0.06789872578803484}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:55:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 07:58:29,777] Trial 29 finished with value: 0.8014455202509205 and parameters: {'n_estimators': 526, 'learning_rate': 0.05748059091907433, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.7922940566276114, 'colsample_bytree': 0.9431614566449158, 'colsample_bylevel': 0.7275285850295604, 'colsample_bynode': 0.7613393991017398, 'reg_alpha': 0.963466607079543, 'reg_lambda': 0.017886247041547836, 'gamma': 0.006999431449442966}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[07:58:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:11:24,146] Trial 30 finished with value: 0.6928951315968908 and parameters: {'n_estimators': 828, 'learning_rate': 0.003055561040415211, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.601618073063316, 'colsample_bytree': 0.9270169408602368, 'colsample_bylevel': 0.663260609026469, 'colsample_bynode': 0.8364319508748781, 'reg_alpha': 2.5638873338845425, 'reg_lambda': 0.008456494348669432, 'gamma': 0.5575887137893186}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:11:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:14:53,119] Trial 31 finished with value: 0.8401745533887904 and parameters: {'n_estimators': 647, 'learning_rate': 0.09986589243309239, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.6830657363695083, 'colsample_bytree': 0.8084072536280381, 'colsample_bylevel': 0.7914051661038535, 'colsample_bynode': 0.6695615305825836, 'reg_alpha': 0.5832104727480868, 'reg_lambda': 0.10423931807526902, 'gamma': 0.21143685682601607}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:14:53] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:18:26,196] Trial 32 finished with value: 0.828037638074458 and parameters: {'n_estimators': 659, 'learning_rate': 0.0628765163077597, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.6960727240197426, 'colsample_bytree': 0.7824300574851603, 'colsample_bylevel': 0.7686637324378278, 'colsample_bynode': 0.6681478955296752, 'reg_alpha': 0.7106127156154955, 'reg_lambda': 0.08800208272213979, 'gamma': 0.12905098140888485}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:18:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:21:40,761] Trial 33 finished with value: 0.7313514250647757 and parameters: {'n_estimators': 430, 'learning_rate': 0.030266759473620213, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.6783777184811136, 'colsample_bytree': 0.9992079747216935, 'colsample_bylevel': 0.9146125682989197, 'colsample_bynode': 0.7876391412671132, 'reg_alpha': 3.5626253346654497, 'reg_lambda': 2.7504625441464627, 'gamma': 0.011529482845875082}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:21:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:26:00,814] Trial 34 finished with value: 0.8379926360289104 and parameters: {'n_estimators': 727, 'learning_rate': 0.06528225311660693, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.7626705687320227, 'colsample_bytree': 0.9606658643595273, 'colsample_bylevel': 0.8308190481921213, 'colsample_bynode': 0.7145705966251487, 'reg_alpha': 0.25884702915010677, 'reg_lambda': 0.035118637956132195, 'gamma': 2.6309242677500833}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:26:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:31:07,114] Trial 35 finished with value: 0.816309832265103 and parameters: {'n_estimators': 894, 'learning_rate': 0.042580526069284266, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.8258588696578911, 'colsample_bytree': 0.9645245081116887, 'colsample_bylevel': 0.82415317253406, 'colsample_bynode': 0.7297286736617394, 'reg_alpha': 0.2285397303113917, 'reg_lambda': 0.05331561462920287, 'gamma': 3.3917628844219925}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:31:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:34:32,732] Trial 36 finished with value: 0.7103504704759307 and parameters: {'n_estimators': 724, 'learning_rate': 0.012461821172642476, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.7853432334787863, 'colsample_bytree': 0.9682652994826969, 'colsample_bylevel': 0.8752275695772599, 'colsample_bynode': 0.71615371826497, 'reg_alpha': 0.46548291126673674, 'reg_lambda': 0.025131048069104475, 'gamma': 1.3600611650499972}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:34:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:38:08,848] Trial 37 finished with value: 0.7568525842083731 and parameters: {'n_estimators': 794, 'learning_rate': 0.026623320582297418, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8368386811392956, 'colsample_bytree': 0.9137389617610782, 'colsample_bylevel': 0.7886948356173988, 'colsample_bynode': 0.689149283184125, 'reg_alpha': 4.527688458808014, 'reg_lambda': 0.009938719426550242, 'gamma': 8.270750446640198}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:38:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:43:20,766] Trial 38 finished with value: 0.8291285967543979 and parameters: {'n_estimators': 653, 'learning_rate': 0.06411281181579724, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.7401734112867763, 'colsample_bytree': 0.939884659240255, 'colsample_bylevel': 0.9122352634469431, 'colsample_bynode': 0.779503964597776, 'reg_alpha': 0.6919025683185267, 'reg_lambda': 0.0365723691835186, 'gamma': 0.06849066447487744}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:43:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n",
            "[I 2025-07-13 08:46:46,616] Trial 39 finished with value: 0.8139915450702304 and parameters: {'n_estimators': 721, 'learning_rate': 0.04267277794102164, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.8785595521205978, 'colsample_bytree': 0.9816384146403226, 'colsample_bylevel': 0.5007898711455379, 'colsample_bynode': 0.6027009404851363, 'reg_alpha': 0.012239101995669079, 'reg_lambda': 0.004357329892393577, 'gamma': 2.0908840633683763}. Best is trial 27 with value: 0.8444020182735579.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning:\n",
            "\n",
            "[08:46:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏃 View run Trial_Best-hp-MaxFeatures-10000_XGBoost_Trigrams_MaxFeatures_10000 at: https://dagshub.com/AMR-ITH/yt-comment-analyzer.mlflow/#/experiments/10/runs/8b7a1f30315c4780957fe896bd294c5f\n",
            "🧪 View experiment at: https://dagshub.com/AMR-ITH/yt-comment-analyzer.mlflow/#/experiments/10\n",
            "Best accuracy for max_features=10000: 0.8444\n",
            "Best parameters: {'n_estimators': 645, 'learning_rate': 0.0992856125849396, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.5701166162393628, 'colsample_bytree': 0.9157799963299006, 'colsample_bylevel': 0.8616852672926257, 'colsample_bynode': 0.6794431506557485, 'reg_alpha': 0.9424389486460987, 'reg_lambda': 0.09160131384298396, 'gamma': 0.07834491853463521}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"98b105bc-cfa9-445b-8cc7-e90644272896\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"98b105bc-cfa9-445b-8cc7-e90644272896\")) {                    Plotly.newPlot(                        \"98b105bc-cfa9-445b-8cc7-e90644272896\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"gamma (FloatDistribution): 0.00029360102390338345\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"colsample_bylevel (FloatDistribution): 0.002044565653504004\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"colsample_bynode (FloatDistribution): 0.0038509316027201235\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"subsample (FloatDistribution): 0.005164041899677573\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"colsample_bytree (FloatDistribution): 0.005688951464236247\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"min_child_weight (IntDistribution): 0.010080535327263697\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_estimators (IntDistribution): 0.01469087454160291\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"reg_lambda (FloatDistribution): 0.020855187890394887\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"max_depth (IntDistribution): 0.05716706739657483\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"reg_alpha (FloatDistribution): 0.10226675555251105\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.7778974876476115\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"\\u003c0.01\",\"0.01\",\"0.01\",\"0.02\",\"0.06\",\"0.10\",\"0.78\"],\"textposition\":\"outside\",\"x\":[0.00029360102390338345,0.002044565653504004,0.0038509316027201235,0.005164041899677573,0.005688951464236247,0.010080535327263697,0.01469087454160291,0.020855187890394887,0.05716706739657483,0.10226675555251105,0.7778974876476115],\"y\":[\"gamma\",\"colsample_bylevel\",\"colsample_bynode\",\"subsample\",\"colsample_bytree\",\"min_child_weight\",\"n_estimators\",\"reg_lambda\",\"max_depth\",\"reg_alpha\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('98b105bc-cfa9-445b-8cc7-e90644272896');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"0604a107-7603-4834-993e-779ee8eea39c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0604a107-7603-4834-993e-779ee8eea39c\")) {                    Plotly.newPlot(                        \"0604a107-7603-4834-993e-779ee8eea39c\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"y\":[0.6065730260466384,0.7314877948997681,0.7329878630846857,0.6678030819582709,0.602891040501841,0.6748943133778809,0.6616664393836084,0.6937133506068458,0.6496658939042683,0.792854220646393,0.6881221873721532,0.8401745533887904,0.8247647620346379,0.8328105822991955,0.7177144415655257,0.775671621437338,0.6701213691531434,0.8359470885040229,0.797763534706123,0.6930315014318833,0.7935360698213555,0.8333560616391654,0.8291285967543979,0.8093549706804855,0.7798990863221056,0.8178099004500204,0.7305332060548206,0.8444020182735579,0.6773489704077458,0.8014455202509205,0.6928951315968908,0.8401745533887904,0.828037638074458,0.7313514250647757,0.8379926360289104,0.816309832265103,0.7103504704759307,0.7568525842083731,0.8291285967543979,0.8139915450702304],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"y\":[0.6065730260466384,0.7314877948997681,0.7329878630846857,0.7329878630846857,0.7329878630846857,0.7329878630846857,0.7329878630846857,0.7329878630846857,0.7329878630846857,0.792854220646393,0.792854220646393,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8401745533887904,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579,0.8444020182735579],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0604a107-7603-4834-993e-779ee8eea39c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 1: Clean data\n",
        "df = df.dropna(subset=['category'])\n",
        "y = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "X_raw = df['clean_comment']\n",
        "\n",
        "# Step 2: Train-test split BEFORE vectorization or resampling\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X_raw, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test, params, trial_number, max_features):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type and trial number with max_features\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"Trial_{trial_number}_{model_name}_Trigrams_MaxFeatures_{max_features}\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "        mlflow.log_param(\"max_features\", max_features)\n",
        "\n",
        "        # Log hyperparameters\n",
        "        for key, value in params.items():\n",
        "            mlflow.log_param(key, value)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # # Save and log the model manually using joblib\n",
        "        # import joblib\n",
        "        # model_filename = \"XGBoost_trial_Best.pkl\"\n",
        "        # joblib.dump(model, model_filename)\n",
        "        # mlflow.log_artifact(model_filename)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "# Step 6: Optuna objective function for XGBoost\n",
        "def objective_xgboost(trial, X_train, X_test, max_features):\n",
        "    # Hyperparameter space to explore\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
        "    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
        "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
        "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
        "    colsample_bylevel = trial.suggest_float('colsample_bylevel', 0.5, 1.0)\n",
        "    colsample_bynode = trial.suggest_float('colsample_bynode', 0.5, 1.0)\n",
        "    reg_alpha = trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True)  # L1 regularization\n",
        "    reg_lambda = trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True)  # L2 regularization\n",
        "    gamma = trial.suggest_float('gamma', 1e-4, 10.0, log=True)  # Minimum loss reduction\n",
        "\n",
        "    # Scale position weight for class imbalance (similar to class_weight='balanced')\n",
        "    class_counts = np.bincount(y_train)\n",
        "    scale_pos_weight = class_counts[0] / class_counts[1] if len(class_counts) > 1 else 1.0\n",
        "\n",
        "    # Log trial parameters\n",
        "    params = {\n",
        "        'n_estimators': n_estimators,\n",
        "        'learning_rate': learning_rate,\n",
        "        'max_depth': max_depth,\n",
        "        'min_child_weight': min_child_weight,\n",
        "        'subsample': subsample,\n",
        "        'colsample_bytree': colsample_bytree,\n",
        "        'colsample_bylevel': colsample_bylevel,\n",
        "        'colsample_bynode': colsample_bynode,\n",
        "        'reg_alpha': reg_alpha,\n",
        "        'reg_lambda': reg_lambda,\n",
        "        'gamma': gamma,\n",
        "        'scale_pos_weight': scale_pos_weight\n",
        "    }\n",
        "\n",
        "    # Create XGBoost model\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        learning_rate=learning_rate,\n",
        "        max_depth=max_depth,\n",
        "        min_child_weight=min_child_weight,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        colsample_bylevel=colsample_bylevel,\n",
        "        colsample_bynode=colsample_bynode,\n",
        "        reg_alpha=reg_alpha,\n",
        "        reg_lambda=reg_lambda,\n",
        "        gamma=gamma,\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='logloss'  # Suppress warnings\n",
        "    )\n",
        "\n",
        "    # # Log each trial as a separate run in MLflow\n",
        "    # accuracy = log_mlflow(\"XGBoost\", model, X_train, X_test, y_train, y_test, params, trial.number, max_features)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Step 7: Run Optuna for XGBoost with different max_features values\n",
        "def run_optuna_experiment():\n",
        "    max_features_list = [3000, 10000]\n",
        "\n",
        "    for max_features in max_features_list:\n",
        "        print(f\"\\n=== Running XGBoost experiment with max_features={max_features} ===\")\n",
        "\n",
        "        # Step 3: Vectorization only on training data with current max_features\n",
        "        vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=max_features)\n",
        "        X_train = vectorizer.fit_transform(X_train_raw)\n",
        "        X_test = vectorizer.transform(X_test_raw)\n",
        "\n",
        "        # Create study for current max_features\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(lambda trial: objective_xgboost(trial, X_train, X_test, max_features),\n",
        "                      n_trials=40)\n",
        "\n",
        "        # Get the best parameters\n",
        "        best_params = study.best_params\n",
        "\n",
        "        # Calculate scale_pos_weight for best model\n",
        "        class_counts = np.bincount(y_train)\n",
        "        scale_pos_weight = class_counts[0] / class_counts[1] if len(class_counts) > 1 else 1.0\n",
        "\n",
        "        best_model = XGBClassifier(\n",
        "            n_estimators=best_params['n_estimators'],\n",
        "            learning_rate=best_params['learning_rate'],\n",
        "            max_depth=best_params['max_depth'],\n",
        "            min_child_weight=best_params['min_child_weight'],\n",
        "            subsample=best_params['subsample'],\n",
        "            colsample_bytree=best_params['colsample_bytree'],\n",
        "            colsample_bylevel=best_params['colsample_bylevel'],\n",
        "            colsample_bynode=best_params['colsample_bynode'],\n",
        "            reg_alpha=best_params['reg_alpha'],\n",
        "            reg_lambda=best_params['reg_lambda'],\n",
        "            gamma=best_params['gamma'],\n",
        "            scale_pos_weight=scale_pos_weight,\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            eval_metric='logloss'\n",
        "        )\n",
        "\n",
        "        # Log the best model with MLflow and print the classification report\n",
        "        best_accuracy = log_mlflow(\"XGBoost\", best_model, X_train, X_test, y_train, y_test,\n",
        "                                  best_params, f\"Best-hp-MaxFeatures-{max_features}\", max_features)\n",
        "\n",
        "        print(f\"Best accuracy for max_features={max_features}: {best_accuracy:.4f}\")\n",
        "        print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "        # Plot parameter importance\n",
        "        optuna.visualization.plot_param_importances(study).show()\n",
        "\n",
        "        # Plot optimization history\n",
        "        optuna.visualization.plot_optimization_history(study).show()\n",
        "\n",
        "# Run the experiment for XGBoost with different max_features\n",
        "run_optuna_experiment()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}